{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # House princing predictions \n",
    " ## Hichem MAIZA\n",
    " ## Part 1 : Linear Regression Vectorized Implimentation From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math \n",
    "import matplotlib.pyplot as plt \n",
    "import random \n",
    "import tensorflow as tf \n",
    "from tensorflow.python.framework import ops\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(variables, train_size = 0.7):\n",
    "    \n",
    "    tmp = math.floor(len(variables)*train_size)\n",
    "    \n",
    "    data = {\n",
    "        \n",
    "        'trainX': (variables.as_matrix().T)[0:2,:tmp],\n",
    "        'trainY': (train_variables.as_matrix().T)[2,:tmp].reshape(1,-1),\n",
    "        'testX' : (variables.as_matrix().T)[0:2,tmp:],\n",
    "        'testY' : (variables.as_matrix().T)[2,tmp:].reshape(1,-1)\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_parameters(X):\n",
    "    '''\n",
    "    A function to initialize the model variables \n",
    "    \n",
    "    Argumenrs :\n",
    "    None \n",
    "    \n",
    "    Output: \n",
    "    param -- initialized values \n",
    "    '''\n",
    "    n_x = X.shape[0]\n",
    "    W = np.random.randn(n_x, 1)\n",
    "    b = np.zeros((1,1))\n",
    "    \n",
    "    param = {\n",
    "        'W':W,\n",
    "        'b':b\n",
    "    }\n",
    "    return param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forword Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forword_propagation(X, param):\n",
    "    '''\n",
    "    A function to compute the forword pass\n",
    "    \n",
    "    Arguments:\n",
    "    X -- matrix of train data \n",
    "    param : parameters of the model \n",
    "    \n",
    "    Outputs\n",
    "    Z -- a vector of liner values\n",
    "    '''\n",
    "    W = param['W']\n",
    "    b = param['b']\n",
    "    Z = np.dot(W.T, X) + b\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The backword Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backword_propagation(Z, Y):\n",
    "    '''\n",
    "    function that computes the cost and derivative\n",
    "    \n",
    "    Arguments: \n",
    "    Z -- Inputvector\n",
    "    Y -- Labels Vector \n",
    "    \n",
    "    Outputs:  \n",
    "    grads -- a dictionnary of gradients values \n",
    "    '''\n",
    "    m = Z.shape[1]\n",
    "    dW = 2/m *np.dot(X,(Z-Y).T)\n",
    "    db = 2/m *np.sum(Z-Y)\n",
    "    \n",
    "    grads = {\n",
    "        'dW':dW,\n",
    "        'db':db\n",
    "    }\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Update parameters function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_parameters(grads,param, learning_rate = 0.001):\n",
    "    \n",
    "    '''\n",
    "    A function for updating parameters \n",
    "    \n",
    "    Arguments:\n",
    "    grads -- A dictionnary of gradient parameters values \n",
    "    param -- A dictionnary of parameters \n",
    "    learning_rate -- the step of the gradient descent \n",
    "    \n",
    "    Returns:\n",
    "    param -- updated parameters\n",
    "    '''    \n",
    "    param['W'] = param['W'] - learning_rate*grads['dW']\n",
    "    param['b'] = param['b'] - learning_rate*grads['db'] \n",
    "    \n",
    "    return param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Global model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X,Y,num_epoch = 500, learning_rate = 0.001):\n",
    "    '''\n",
    "    Linear regression Model : \n",
    "    \n",
    "    Arguments\n",
    "    X -- matrix of features\n",
    "    Y -- vector of labels \n",
    "    num_epoch -- the number of times the gradient descent will execute \n",
    "    learning_rate -- the step of the gradient descent \n",
    "            \n",
    "    Outputs: \n",
    "    param  -- The Updated parameters\n",
    "    '''\n",
    "    param  = init_parameters(X)\n",
    "    \n",
    "    for i in range(num_epoch):\n",
    "        \n",
    "        Z = forword_propagation(X, param)\n",
    "        grads = backword_propagation(Z, Y)\n",
    "        param = update_parameters(grads,param, learning_rate)\n",
    "    \n",
    "    return param "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_train = pd.read_csv('train.csv') \n",
    "test = pd.read_csv('test.csv') \n",
    "correlatedVlues = houses_train.corr()\n",
    "selectedValues = (correlatedVlues['SalePrice'].sort_values(ascending=False)).head(3) \n",
    "MostCorrelated = [selectedValues.index[1],selectedValues.index[2]]\n",
    "train_variables = houses_train[[MostCorrelated[0],MostCorrelated[1],'SalePrice']].astype(float)\n",
    "data = split_data(train_variables, train_size = 0.7)\n",
    "\n",
    "X = data['trainX']\n",
    "Y = data['trainY'] \n",
    "\n",
    "X_test = data['testX']\n",
    "Y_test = data['testY']\n",
    "\n",
    "x = X/np.max(X)\n",
    "y = Y/np.max(Y) \n",
    "\n",
    "x_test = X_test/np.max(X_test)\n",
    "y_test = Y_test/np.max(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': array([[ 0.0008778]]), 'W': array([[ 1.9982101 ],\n",
      "       [ 0.73315763]])}\n"
     ]
    }
   ],
   "source": [
    "param = model(x,y,num_epoch = 500, learning_rate = 0.001)\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Linear Regression Using tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define Place Holders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_create_placeholders():\n",
    "    \n",
    "    '''\n",
    "    A function to define place holders \n",
    "    \n",
    "    Arguments : \n",
    "    --None--\n",
    "    \n",
    "    Outputs : \n",
    "    X : a palce holder for the training examples \n",
    "    Y : a place holder for the labels \n",
    "    '''\n",
    "\n",
    "    X = tf.placeholder(dtype= 'float', shape=[2,None], name='X')\n",
    "    Y = tf.placeholder(dtype= 'float', shape=[1,None], name='Y')\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_initialze_variable(name='Variables') : \n",
    "    \n",
    "    '''\n",
    "    A function to initiaize the model parameters\n",
    "    \n",
    "    Argument :\n",
    "    --Name-- For tensorboard purpose \n",
    "    \n",
    "    Outputs : \n",
    "    params -- A dictionnary of parameters \n",
    "    '''\n",
    "    \n",
    "    with tf.name_scope(name) : # for tensor board purpose\n",
    "        \n",
    "        tf.set_random_seed(1) \n",
    "        W = tf.get_variable('W', [1,2], initializer = tf.contrib.layers.xavier_initializer(seed = 1)) \n",
    "        b = tf.get_variable('b', [1,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "\n",
    "        params = {\n",
    "            'W':W,\n",
    "            'b':b\n",
    "        }\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forword Pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_forword_propagation(X,params) :\n",
    "    \n",
    "    '''\n",
    "    Argument \n",
    "    X --  A place holder for training example \n",
    "    params -- a dictionnary of variables\n",
    "    OUtput \n",
    "    Z -- function output value\n",
    "    '''\n",
    "    W = params['W']\n",
    "    b = params['b']\n",
    "    \n",
    "    Z  = tf.add(tf.matmul(W,X), b) \n",
    "    \n",
    "    return Z \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the cost function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_compute_cost(Z,Y,name = 'cost'):\n",
    "    \n",
    "    with tf.name_scope(name):\n",
    "        cost = tf.reduce_mean((Z-Y)**2)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define mini batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batches(X, Y, mini_batch_size = 64, seed = 0) :\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data\n",
    "    Y -- true \"label\" vector\n",
    "    mini_batch_size -- size of the mini-batches\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # to get the same result every time so i can verify my results       \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.d\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:,k*mini_batch_size:k*mini_batch_size + mini_batch_size ]\n",
    "        mini_batch_Y = shuffled_Y[:,k*mini_batch_size:k*mini_batch_size + mini_batch_size ]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:,num_complete_minibatches*mini_batch_size:]\n",
    "        mini_batch_Y = shuffled_Y[:,num_complete_minibatches*mini_batch_size:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Global Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_model (x,y, learning_rate = 0.001, epoch = 3000, mini_batch_size = 64) :  \n",
    "    seed = 3\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    # create place holders \n",
    "    X, Y = tf_create_placeholders() \n",
    "    # initialize parameters \n",
    "    params = tf_initialze_variable()\n",
    "    # Prform a forword pass\n",
    "    Z = tf_forword_propagation(X,params)\n",
    "    # define cost function \n",
    "    cost = tf_compute_cost(Z,Y,'cost') \n",
    "    # define train optimizer\n",
    "    \n",
    "    with tf.name_scope('train'):\n",
    "        train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost) \n",
    "        \n",
    "    #initialize all variables \n",
    "    init = tf.global_variables_initializer() \n",
    "    costs = []\n",
    "    \n",
    "    with tf.Session() as sess: \n",
    "        sess.run(init)\n",
    "        minibatches = random_batches(x, y, mini_batch_size, seed)\n",
    "        for i in range(epoch):\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _,c= sess.run([train,cost],feed_dict={X:minibatch_X , Y:minibatch_Y})    \n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (i, c))\n",
    "            if i % 5 == 0:\n",
    "                costs.append(c)\n",
    "        \n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        writer = tf.summary.FileWriter('./train') \n",
    "        writer.add_graph(sess.graph)\n",
    "        # lets save the parameters in a variable        \n",
    "        \n",
    "        params = sess.run(params)\n",
    "        print (\"Parameters have been trained!\")\n",
    "               \n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.494372\n",
      "Cost after epoch 100: 0.040136\n",
      "Cost after epoch 200: 0.035965\n",
      "Cost after epoch 300: 0.032326\n",
      "Cost after epoch 400: 0.029130\n",
      "Cost after epoch 500: 0.026324\n",
      "Cost after epoch 600: 0.023857\n",
      "Cost after epoch 700: 0.021689\n",
      "Cost after epoch 800: 0.019781\n",
      "Cost after epoch 900: 0.018101\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzJocCmZm1vT/AWVh9BDCS46gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4138bf0358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "{'b': array([[ 0.31918105]], dtype=float32), 'W': array([[-1.25426805, -0.22813606]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "params = tf_model (x,y, learning_rate = 0.001, epoch = 1000, mini_batch_size = 32) \n",
    "print(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
